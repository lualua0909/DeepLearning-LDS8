{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 9: Face Detection - Haar - Camera.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPq+qHGGwMIcbIOdtokURxw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lualua0909/DeepLearning-LDS8/blob/main/Week_5/Chapter_9_Face_Detection_Haar_Camera.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ3L8Uz6EhMP",
        "outputId": "bb13460c-ddb0-4645-fed2-7cd93ac60190"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2-GM-nDD9c2"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OasirpteEB_U"
      },
      "source": [
        "face_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/haarcascade_eye.xml')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D8-Lw-sFCUi"
      },
      "source": [
        "def detect(gray, frame): # We create a function that takes as input the image in\n",
        "  faces = face_cascade.detectMultiScale(gray, 1.3, 5) # We apply the detectMult\n",
        "  for (x, y, w, h) in faces: # For each detected face:\n",
        "    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2) # We paint a rec\n",
        "    roi_gray = gray[y:y+h, x:x+w] # We get the region of interest in the blac\n",
        "    roi_color = frame[y:y+h, x:x+w] # We get the region of interest in the co\n",
        "    eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 3) # We apply the dete\n",
        "    for (ex, ey, ew, eh) in eyes: # For each detected eye:\n",
        "      cv2.rectangle(roi_color,(ex, ey),(ex+ew, ey+eh), (0, 255, 0), 2)\n",
        "\n",
        "  return frame # We return the image with the detector rectangles."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "cDLXtHnpFI69",
        "outputId": "ed5dec75-847e-48ce-da09-aff48c727ca7"
      },
      "source": [
        "video_capture = cv2.VideoCapture(0) # We turn the webcam on.\n",
        "\n",
        "while True: # We repeat infinitely (until break):\n",
        "  _, frame = video_capture.read() # We get the last frame.\n",
        "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # We do some colour transforma\n",
        "  canvas = detect(gray, frame) # We get the output of our detect function.\n",
        "  cv2.imshow('Video', canvas) # We display the outputs.\n",
        "  if cv2.waitKey(1) & 0xFF == ord('q'): # If we type on the keyboard:\n",
        "    break # We stop the loop.\n",
        "    \n",
        "video_capture.release() # We turn the webcam off.\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-10bf35bd83d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# We repeat infinitely (until break):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_capture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# We get the last frame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# We do some colour transforma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mcanvas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# We get the output of our detect function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Video'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# We display the outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPxHY5S_FVlG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}